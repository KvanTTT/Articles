# Идеальный генератор парсеров

### Иван Кочуркин

### Московский Государственный Технический Университет им Н.Э. Баумана

## Введение

В настоящее время существует несколько генераторов парсеров, основанных на
разных технологиях: ANTLR, PEG, Yacc, Bison и другие. Одним из самых популярных,
пожалуй, является ANTLR. Он поддерживает LL(*)
грамматики, левую рекурсию, семантические действия и предикаты, а также имеет
много других возможностей. Он существует уже более 20 лет, а в 2013
году вышла его 4-я версия. Сейчас его разработка ведется на GitHub. В данный
момент он позволяет генерировать парсеры под многие языки (рантаймы)
Java, C#, Python2, Python3, JavaScript, C++, Swift и Go.

Помимо непосредственно генератора, для ANTLR разработано большое количество
грамматик как для небольших предметно-ориентированных языков (DSL), так и для
полноценных и сложных языков программирования.

Эти грамматики достаточно востребованы как в мире открытого ПО,
так и в коммерческой разработке. Например, грамматики PHP, PL/SQL, T-SQL
используются в открытом универсальном движке сопоставления с шаблонами
[PT.PM](https://github.com/PositiveTechnologies/PT.PM), а также в
проприетарном движке анализа потоков данных
[PT Application Inspector](https://www.ptsecurity.com/products/#ai) на нем основанном.
Грамматика Objective-C используется в [Swiftify](https://swiftify.com/),
веб-сервисе по преобразованию Objective-C
кода в Swift. По истории изменений видно что грамматики улучаются не только
коммерческой компанией, но и большим количеством сторонних разработчиков.

Сейчас автор - один из мэинтейнеров репозитория грамматик [grammars-v4](https://github.com/antlr/grammars-v4/).
Он разработал грамматики
PHP, T-SQL, а также сильно улучшил грамматики JavaScript, Java8, PL/SQL,
Objective-C и C#. Во время разработки автор и другие контрибьютеры столкнулись с
большим количеством проблем, часть из которых удалось решить средствами ANTLR,
но не все.

Самой большой проблемой по мнению автора является неуниверсальность грамматик
при использовании *вставок кода*, зависимых от рантайма. Такие вставки
необходимы для корректного парсинга многих конструкций. Например,
обработка интерполяционных строк в PHP и C# сильно зависит от контекста и
адаптировать под них контекстно-свободные грамматики никак нельзя. Универсальность
очень важна, поскольку позволяет не только пользоваться одной грамматикой под
несколько языков, но и привлекает новых контрибьютеров для разработки и
тестирования грамматики.

Помимо универсальных вставок у автора есть соображения о расширении синтаксиса
описания грамматик. Например, *оператор проверки значения* токена (лексемы)
сильно бы облегчил грамматики языков с большим обилием ключевых слов, а именно SQL
диалектов (T-SQL, PL/SQL)

Более того, у автора есть идеи по поводу того, как можно доработать синтаксис описания
лексических правил, реализовать связь скрытых и ошибочных токенов с узлами дерева
разбора для получения достоверного дерева, как сделать генерируемый код более
нативным для рантайма, как разрабатывать парсеры без токенов и другие мысли.

Автор высказывает мнение не только относительно дальнейшего развития ANTLR, но и
относительно развития инфраструктуры парсеров в целом. В частности, делится
соображениями по поводу онлайн-обозревателя и редактора грамматик.

## Проблемы современных парсеров

* Только контекстно-свободные грамматики

## Предложения

* Неоднозначность
* Лексер: удобное задание комментариев.
* Универсальность:
  * Оператор проверки значения предыдущего токена
  * Универсальные вставки кода:
* Конфликтующие грамматические правила в разных рантаймах
* Достоверное дерево разбора (по аналогии с Roslyn)
* Веб-версии для тестирования грамматик, получения деревьев разбора
* Чувствительность к регистру (ключевые слова и идентификаторы)
* Парсер без токенов (для Markdown и подобного) https://github.com/antlr/antlr4/issues/814

### Лексер

### Парсинг без токенов

Существуют языки и синтаксические конструкции, в которых стадии токенизации,
парсинга и семантического анализа сильно переплетены. Например, в С-языках
следующая конструкция `x * y` может интерпретироваться и как умножение, и как
объявление указателя: данная неоднозначность разрешается с использованием таблицы
символов.

А в текстовом формате Markdown вообще не существует ошибок парсинга: там каждый
символ интерпретируется либо как символ, который используется либо для обозначения
либо как-то элемента, либо же трактуется как обычный текст.

Например, если написать так `[ссылка](https://google.com)`, то в результате
это преобразуется в [ссылку](https://google.com). Если же убрать последнюю скобку,
то данный синтаксис просто текстом [ссылка](https://google.com.

Да, если рассматривать сами символы как токены, то это может повлечь проблемы
в производительности, однако идеальный генератор парсеров должен поддерживать и
такие грамматики.

* [Add scannerless tokenizer to runtime jar](https://github.com/antlr/antlr4/issues/814)

### Универсальность

#### Оператор проверки значения токена

Во многих языках, например в SQL диалектах, существует большое количество
ключевых слов, которые в определенных случая могут являться идентификаторами.
Классическое решение данной проблемы - заносить все такие ключевые слова в
правило идентификатора:

```antlr
identifier
    : ID
    : GET
    ;
```

Однако хотя такое решение и универсально, оно далеко не идеально, т.к. ключевых
контекстных ключевых слов может быть очень много (T-SQL, PL/SQL), и можно попросту
забыть про какое-то. Более того, большое количество альтернатив может замедлить
работу парсера.

Другой способ заключается в получении значения идентификатора и распознавании
нужного правила в зависимости от него. Это можно сделать только с помощью вставки
кода:

```antlr
getter
    : {_input.LT(1).getText().equals("get")}? Identifier propertyName
    ;
```

В настоящий момент вставки кода в ANTLR runtime-dependent, т.е. если при
использовании вставок грамматика будет валидна только для java рантайма.

Для того чтобы избежать такой зависимости и сделать грамматику по настоящему
универсальной, предлагается ввести специальную конструкцию для сравнения значения
токена с определенным значением:

```antlr
getter
    : Identifier=='get' propertyName
    ;
```

Стоит отметить, что в конструкции выше сравнение будет выполняться *после*
распознавания идентификатора. Для предшествующего сравнения можно, например,
использовать такой синтаксис: `'get'==Identifier`.

Оператор сравнения значений токена решает вопрос с ключевыми словами, однако не
решает проблемы распознавания контекстно-зависимых грамматик в целом, поэтому
предлагается ввести в целом **универсальные вставки кода**.

* [Token value comparison operator](https://github.com/antlr/antlr4/issues/1965)

#### Конструкция Heredoc в PHP

Бывают ситуации, когда без вставок кода просто никак не обойтись. Например,
при парсинге конструкций [Heredoc](http://php.net/manual/en/language.types.string.php)
в PHP и интерполяции строк в C#.

```php
<?php
    foo(<<< HEREDOC
        Heredoc line 1.
        HEREDOC
)   ;
?>
```

Смысл заключается в том что для завершения распознавания правила необходимо
знать значение открывающего токена. Это можно сделать например так:

```antlr
heredoc:
    '<<<' start=identifier
    (.!=start)*
    .==start // or just .
    ';'
```

Здесь точка обозначает произвольный токен.

#### Универсальные вставки кода

Однако существуют синтаксические конструкции, которые охватить даже
дополнительным синтаксисом, а нужно использовать какие-то вычисления для
корректного парсинга. Например, выражение `x * y` в C или *интерполяция строк*
в C# или PHP. В ANTLR для таких вычислений принято использовать *семантические
предикаты* или *действия*, однако они не являются универсальными.

С помощью определенных трюков их можно обобщить на несколько рантаймов, как это
сделано в грамматике [JavaScript](https://github.com/antlr/grammars-v4/tree/master/javascript).
Однако такой подход не является идеальным, поскольку абстрагирование парсера -
это дополнительный сложный этап. Такие вставки кода все равно являются чужеродными,
они плохо интегрируются в сгенерированный код, т.к. такой код не
проверяется во время генерации парсера из грамматики, плохо форматируется. Кроме
того, грамматические IDE не могут хорошо работать с такими языковыми вставками.

Автором предлагается иной подход, а именно, создание универсального DSL для
семантических предикатов. Такой DSL будет решать все вышеперечисленные проблемы
и буде лаконичным. Благодаря симбиозу декларативного подхода (сама контекстно-свободная)
грамматика и императивного, можно будет удобно разрабатывать парсеры на все
случаи жизни.

* [Unified Actions Language](https://github.com/antlr/antlr4/issues/1045).

### Соблюдение стиля кода рантайма

В ANTLR лексические правила записываются с первой буквой в верхнем регистре, а
правила парсера - в нижнем. Других ограничений на именование правил нет.
В настоящее время так сложилось, что грамматические правила SQL диалектов
(PL/SQL, T-SQL, SQLite) записаны в SnackCase, т.е с использованием символов
подчеркивания.

В разных языках приняты разные правила именования. Как правило,
в C# методы начинаются с большой буквы, в Java - с маленькой. Но настоящая
версия ANTLR не учитывает эти различия .

Более того, из-за универсальности грамматик сгенерированный код вообще оказаться
невалидным из-за того, что в каких-то рантаймах определенные идентификаторы
могут быть зарезервированы под ключевые слова. Несмотря на то, что в основном
при генерации парсера под определенный рантайм и при конфликтующих словах будет
выводиться ошибка, это вызывает неудобства, т.к. под правила нужно будет
переименовывать таким образом, чтобы они не конфликтовали с ключевыми словами в
идеале из всех рантаймов. Кстати, вопросы про это появляются довольно часто и
для них даже специально была создана метка
[symbol-conflict](https://github.com/antlr/grammars-v4/issues?utf8=%E2%9C%93&q=label%3Asymbol-conflict+)
в репозитории грамматик.

Автор предлагает менять правила не в самой грамматике, а адаптировать
идентификаторы под каждый конкретный рантайм. Таким образом, грамматика не будет
никак зависеть от рантайма, а код визиторов не будет похож на сгенерированный.

* [Add a new option for naming convention of generated Visitor and Listener methods](https://github.com/antlr/antlr4/issues/1615)
* [Throw warning if symbol conflicts with generated code in another language or runtime](https://github.com/antlr/antlr4/issues/1670)

### Достоверное дерево разбора

В ANTLR есть механизм каналов, который позволяет изолировать множество скрытых
токенов (пробелов, комментариев) от основных. Однако такие токены не привязаны к
узлам дерева разбора, которое получается в результате парсинга. Кроме скрытых,
есть еще и нераспознанные (ошибочные) символы, для которых не подошло ни одно
лексическое правило.

Связанность таких токенов с узлами дерева разбора очень важна, т.к. благодаря
такой структуре становится возможным, например, учитывать стиль кода при его
трансформациях и рефакторинге. Более того, анализируя лишь только дерево разбора
и пробелы, можно обнаружить серьезные уязвимости в исходных кодах, например,
[goto fail](https://nakedsecurity.sophos.com/2014/02/24/anatomy-of-a-goto-fail-apples-ssl-bug-explained-plus-an-unofficial-patch/).

Также благодаря скрытым и ошибочным токенам становится возможным строить
*достоверное* дерево разбора, а именно дерево, которое может быть преобразовано
обратно в код символ в символ.

* [Create parse trees whose leaves have left/right hidden token text](https://github.com/antlr/antlr4/pull/1667)
* [Error recovery should create missing tokens for first path to recovery point](https://github.com/antlr/antlr4/issues/1972)

## Онлайн обозреватель грамматик

Для разработки и отладки ANTLR грамматик существует плагины к популярным IDE:
ANTLRWorks, ANTLR intellij-plugin-v4, ANTLR Eclipse Plugin. Однако все они
обладают определенными недостатками: не позволяют разрабатывать грамматики без
IDE, редакторов кода и сразу под все рантаймы, и, самое главное, они работают
оффлайн. Т.е. чтобы иметь возможность что-то протестировать, пользователю
необходимо устраивать и настраивать какие-то дополнительные инструменты.
Для решения этих проблем было разработано
приложение с открытым исходным кодом, [Desktop Antlr Grammar Editor
(DAGE)](https://github.com/KvanTTT/DAGE). Оно позволяет полностью проверять
грамматику на следующих уровнях:

* проверка корректности синтаксиса грамматики;
* проверка семантики с помощью ANTLR;
* проверка ошибок компиляции сгенерированных файлов;
* непосредственно проверка ошибок парсинга.

Данная декомпозиция этапов проверки с одной стороны позволяет достичь
оптимальной скорости работы приложения, а с другой - предоставляет возможность
найти все ошибки грамматики с помощью всего лишь одного действия. В ходе
разработки потребовалось решить несколько технических задач, например, задачу
мэппинга текстовых файлов для отображения релевантной ошибки компиляции в файле
грамматики. Кроме того, одна из главных целей DAGE заключалась в решении проблем
парсинга, затронутых в этом тексте. Таким образом, он поддерживает
регистронезависимые языки и языки с препроцессингом, а также позволяет проверять
корректность грамматик сразу под все рантаймы.

В перспективе разработать веб-версию редактора грамматик для того, чтобы любой
начинающий разработчик парсеров мог быстро и просто приступить к созданию своей
собственной грамматики прямо в браузере, не разбираясь в дополнительных зависимостях.
А при желании эту грамматику можно будет сразу расшарить для других более продвинутых
пользователей, что позволит им сразу понять, почему парсер работает некорректно.

## Заключение

