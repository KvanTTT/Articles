# Идеальный генератор парсеров

<!-- TOC -->

- [Оператор проверки значения токена](#оператор-проверки-значения-токена)
    - [Конструкция Heredoc в PHP](#конструкция-heredoc-в-php)
- [Универсальные вставки кода](#универсальные-вставки-кода)
- [Достоверное дерево разбора](#достоверное-дерево-разбора)
- [Соблюдение стиля кода рантайма](#соблюдение-стиля-кода-рантайма)
- [Парсинг без токенов](#парсинг-без-токенов)
- [Онлайн редактор и обозревать грамматик](#онлайн-редактор-и-обозревать-грамматик)
- [Заключение](#заключение)

<!-- /TOC -->

## Оператор проверки значения токена

Во многих языках, например в SQL диалектах, существует большое количество
слов, которые являются ключевыми, но только в определенных контекстах.
Классическое решение данной проблемы - заносить все такие ключевые слова в
правило идентификатора:

```antlr
identifier
    : ID
    : GET
    ;
```

Несмотря на то, что такое решение и универсально, оно далеко не идеально, т.к. ключевых
контекстных ключевых слов может быть очень много (T-SQL, PL/SQL), и можно попросту
забыть про какое-то. Более того, большое количество альтернатив может замедлить
работу парсера.

Другой способ заключается в получении значения токена-идентификатора и распознавании
нужного правила в зависимости от него. Это можно сделать только с помощью вставки
кода:

```antlr
getter
    : {_input.LT(1).getText().equals("get")}? Identifier propertyName
    ;
```

К сожалению, такие вставки кода в ANTLR зависимы от рантайма, т.е. если при
использовании вставок грамматика будет валидна только для java рантайма.

Для того чтобы избежать такой зависимости и сделать грамматику по настоящему
универсальной, можно ввести специальную конструкцию для сравнения значения
токена с определенным:

```antlr
getter
    : Identifier=='get' propertyName
    ;
```

Оператор сравнения значений токена решает вопрос с ключевыми словами, однако не
решает проблемы распознавания контекстно-зависимых грамматик в целом.

Эта фича также предложена на GitHub: [Token value comparison operator](https://github.com/antlr/antlr4/issues/1965).

### Конструкция Heredoc в PHP

Бывают ситуации, когда без вставок кода просто не обойтись. Например, при парсинге
конструкций [Heredoc](http://php.net/manual/en/language.types.string.php)
в PHP и интерполяции строк в C#.

```php
<?php
    foo(<<< HEREDOC
        Heredoc line 1.
        HEREDOC
)   ;
?>
```

Для завершения распознавания правила необходимо знать значение открывающего токена.
Это можно сделать, например, так:

```antlr
heredoc:
    '<<<' start=identifier
    (.!=start)*
    .==start // or just .
    ';'
```

Здесь точка обозначает произвольный токен.

## Универсальные вставки кода

Cуществуют синтаксические конструкции, которые не охватить даже дополнительным
синтаксисом, а нужно использовать какие-то вычисления для корректного парсинга.
Например,  *интерполяция строк* в C# или PHP. В ANTLR для таких вычислений
принято использовать *семантические предикаты* или *действия*. Однако они не
являются универсальными.

С помощью определенных трюков их можно обобщить на несколько рантаймов, как это
сделано в грамматике ANTLR [JavaScript](https://github.com/antlr/grammars-v4/tree/master/javascript).
Однако такой подход не является идеальным, поскольку абстрагирование парсера -
это дополнительный сложный этап. Такие вставки кода все равно являются чужеродными,
они плохо интегрируются со сгенерированным кодом, т.к. он не проверяется во время
генерации парсера из грамматики, плохо форматируется. Кроме того, грамматические
IDE не могут хорошо работать с ними.

Можно воспользоваться универсальным DSL для описания семантических предикатов
Он будет решать все вышеперечисленные проблемы, а, с другой стороны, будет
лаконичным, более заточенным под специфику парсеров. Благодаря симбиозу
декларативного подхода (сама контекстно-свободная грамматика) и императивного,
можно будет удобно разрабатывать парсеры на всевозможные случаи!

Например, инструкция `la(-1)`, взятие предыдущего символа, будет транслироваться
в код `_input.LA(-1)` на Java рантайме и в код `self._input.LA(1)` в Python
рантайме. Более подробне про универсальные вставки кода и DSL расписано на
[GitHub](https://github.com/antlr/antlr4/issues/1045).

## Достоверное дерево разбора

В ANTLR есть механизм каналов, который позволяет изолировать множество скрытых
токенов (пробелов, комментариев) от основных. Однако такие токены не привязаны к
узлам дерева разбора, которое получается в результате парсинга. Кроме скрытых,
есть еще и нераспознанные (ошибочные) символы, для которых не подошло ни одно
лексическое правило.

Связанность таких токенов с узлами дерева разбора очень важна, т.к. благодаря
такой структуре становится возможным, например, учитывать стиль кода при его
трансформациях и рефакторинге. Более того, анализируя лишь только дерево разбора
и пробелы, можно обнаружить серьезные недостатки в исходных кодах, например,
[goto fail](https://nakedsecurity.sophos.com/2014/02/24/anatomy-of-a-goto-fail-apples-ssl-bug-explained-plus-an-unofficial-patch/).

Также благодаря скрытым и ошибочным токенам становится возможным строить
*достоверное* дерево разбора, а именно дерево, которое может быть преобразовано
обратно в код символ в символ.

Подробнее на GitHub:

* [Create parse trees whose leaves have left/right hidden token text](https://github.com/antlr/antlr4/pull/1667)
* [Error recovery should create missing tokens for first path to recovery point](https://github.com/antlr/antlr4/issues/1972)

## Соблюдение стиля кода рантайма

В ANTLR лексические правила записываются с первой буквой в верхнем регистре, а
правила парсера - в нижнем. Других ограничений на именование правил нет.
В настоящее время так сложилось, что грамматические правила SQL диалектов
(PL/SQL, T-SQL, SQLite) записаны в SnackCase, т.е с использованием символов
подчеркивания.

В разных языках приняты разные правила именования. Как правило,
в C# методы начинаются с большой буквы, в Java - с маленькой. Но ANTLR не
учитывает эти различия.

Более того, из-за универсальности грамматик сгенерированный код вообще оказаться
невалидным из-за того, что в каких-то рантаймах определенные идентификаторы
могут быть зарезервированы под ключевые слова. Несмотря на то, что в основном
при генерации парсера под определенный рантайм и при конфликтующих словах будет
выводиться ошибка, это вызывает неудобства, т.к. под правила нужно будет
переименовывать таким образом, чтобы они не конфликтовали с ключевыми словами в
идеале из всех рантаймов. Кстати, вопросы про это появляются довольно часто и
для них даже специально была создана метка
[symbol-conflict](https://github.com/antlr/grammars-v4/issues?utf8=%E2%9C%93&q=label%3Asymbol-conflict+)
в репозитории грамматик.

Можно  менять правила не в самой грамматике, а адаптировать идентификаторы под
каждый конкретный рантайм. Таким образом, грамматика не будет никак зависеть от
рантайма, а код визиторов не будет похож на сгенерированный.

Подробнее на GitHub:

* [Add a new option for naming convention of generated Visitor and Listener methods](https://github.com/antlr/antlr4/issues/1615)
* [Throw warning if symbol conflicts with generated code in another language or runtime](https://github.com/antlr/antlr4/issues/1670)

## Парсинг без токенов

Существуют языки и синтаксические конструкции, в которых стадии токенизации,
парсинга и семантического анализа сильно переплетены. Например, в С-языках
следующая конструкция `x * y` может интерпретироваться и как умножение, и как
объявление указателя: данная неоднозначность разрешается с использованием таблицы
символов.

А в текстовом формате Markdown вообще не существует ошибок парсинга: там каждый
символ интерпретируется либо как символ, который используется либо для обозначения
либо как-то элемента, либо же трактуется как обычный текст.

Например, если написать так `[ссылка](https://google.com)`, то в результате
это преобразуется в [ссылку](https://google.com). Если же убрать последнюю скобку,
то данный синтаксис просто текстом [ссылка](https://google.com.

Да, если рассматривать сами символы как токены, то это может повлечь проблемы
в производительности, однако идеальный генератор парсеров должен поддерживать и
такие грамматики.

Предложение на GitHub: [Add scannerless tokenizer to runtime jar](https://github.com/antlr/antlr4/issues/814).

## Онлайн редактор и обозревать грамматик

Для разработки и отладки ANTLR грамматик существует плагины к популярным IDE,
например [ANTLR intellij-plugin-v4](https://plugins.jetbrains.com/plugin/7358-antlr-v4-grammar-plugin),
[vscode-antlr4](https://marketplace.visualstudio.com/items?itemName=mike-lischke.vscode-antlr4).
Однако они обладают определенными недостатками: не позволяют разрабатывать
грамматики без IDE, сразу под все рантаймы, и, самое главное, они работают
оффлайн. Т.е. для того, чтобы чтобы иметь возможность что-то протестировать,
пользователю необходимо устраивать и настраивать дополнительные инструменты.

Было бы намного удобнее тестировать грамматики для простых DSL и для полноценных
языков программирования сразу онлайн, в браузере. В этом случае
у пользователя был бы выбор: создать свой язык или воспользоваться уже готовой
грамматикой из репозитория, чтобы посмотреть дерево разбора для определенного
фрагмента кода. Можно даже ввести функциональность PR фикса грамматик сразу
в репозиторий.

В качестве альтернатив существует сервис <http://astexplorer.net/>, однако в
нем строится дерево разбора только для определенных языков (JavaScript),
а грамматики менять нельзя. <https://sharplab.io/> позволяет в реальном времени
наблюдать в какой низкоуровневый код компилируется программа.

Таким образом, начинающий разработчик сможет быстро и просто приступить к созданию
собственной грамматики прямо в браузере, а опытный сможет оперативно помочь с
фиксами грамматик в официальном репозитории.

В качестве демонстрации концепта было разработано десктопное приложение с
открытым исходным кодом, [Desktop Antlr Grammar Editor (DAGE)](https://github.com/KvanTTT/DAGE),
которое позволяет полностью проверять грамматику на нескольких уровнях:

* проверка корректности синтаксиса грамматики;
* проверка семантики с помощью ANTLR;
* проверка ошибок компиляции сгенерированных файлов;
* непосредственно проверка ошибок парсинга.

Данная декомпозиция этапов проверки с одной стороны позволяет достичь
оптимальной скорости работы приложения, а с другой - предоставляет возможность
поиска всех ошибок грамматики с помощью всего лишь одного действия.

## Заключение

Генератор парсеров с универсальными семантическими предикатами и возможностью быстрого
редактирования грамматики прямо в браузере сильно автоматизирует и упрощает
процесс разработки грамматик для любых целей, снижает порога входа в предметную
область и привлекает большое количество как начинающих, так и опытных разработчиков.